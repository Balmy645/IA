{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargadas 1400 imágenes con dimensiones (48, 48, 1)\n",
      "Conjunto de entrenamiento: 1120 imágenes\n",
      "Conjunto de prueba: 280 imágenes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Ruta al directorio de datos\n",
    "data_dir = 'C:\\\\datasets\\\\archive\\\\train'\n",
    "\n",
    "# Lista de etiquetas de emociones\n",
    "emotions = ['happy', 'sad', 'surprise', 'angry', 'disgust', 'fear', 'neutral']\n",
    "\n",
    "# Dimensiones deseadas de las imágenes\n",
    "img_size = (48, 48)\n",
    "\n",
    "# Inicializar listas para las imágenes y etiquetas\n",
    "faces = []\n",
    "labels = []\n",
    "\n",
    "# Función para cargar imágenes en lotes\n",
    "def load_images_batch(emotion_dir, emotion_label, batch_size=100):\n",
    "    batch_faces = []\n",
    "    batch_labels = []\n",
    "    img_files = os.listdir(emotion_dir)[:200]  # Limitar a 100 imágenes por categoría\n",
    "    \n",
    "    for i, img_name in enumerate(img_files):\n",
    "        img_path = os.path.join(emotion_dir, img_name)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, img_size)  # Redimensionar la imagen\n",
    "            batch_faces.append(img)\n",
    "            batch_labels.append(emotion_label)\n",
    "        else:\n",
    "            print(f\"Error al cargar la imagen {img_path}\")\n",
    "        \n",
    "        # Procesar en lotes\n",
    "        if (i + 1) % batch_size == 0 or (i + 1) == len(img_files):\n",
    "            yield np.array(batch_faces), np.array(batch_labels)\n",
    "            batch_faces, batch_labels = [], []\n",
    "\n",
    "# Cargar las imágenes y etiquetas en lotes\n",
    "for emotion in emotions:\n",
    "    emotion_dir = os.path.join(data_dir, emotion)\n",
    "    if not os.path.exists(emotion_dir):\n",
    "        print(f\"La carpeta {emotion_dir} no existe, revisa la ruta.\")\n",
    "        continue\n",
    "\n",
    "    for batch_faces, batch_labels in load_images_batch(emotion_dir, emotions.index(emotion)):\n",
    "        faces.extend(batch_faces)\n",
    "        labels.extend(batch_labels)\n",
    "\n",
    "# Convertir las listas a arrays de numpy\n",
    "faces = [img.reshape(img_size[0], img_size[1], 1) for img in faces]\n",
    "faces = np.array(faces)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Normalizar las imágenes\n",
    "faces = faces.astype('float32') / 255.0\n",
    "\n",
    "print(f\"Cargadas {faces.shape[0]} imágenes con dimensiones {faces.shape[1:]}\")\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "faces_train, faces_test, labels_train, labels_test = train_test_split(faces, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Conjunto de entrenamiento: {faces_train.shape[0]} imágenes\")\n",
    "print(f\"Conjunto de prueba: {faces_test.shape[0]} imágenes\")\n",
    "\n",
    "\n",
    "# Crear el modelo de Eigenfaces\n",
    "model = cv2.face.EigenFaceRecognizer_create()\n",
    "\n",
    "# Convertir las etiquetas a formato adecuado\n",
    "labels_train = np.array(labels_train, dtype=np.int32)\n",
    "labels_test = np.array(labels_test, dtype=np.int32)\n",
    "\n",
    "# Aplanar las imágenes para el entrenamiento\n",
    "faces_train_flatten = [img.flatten() for img in faces_train]\n",
    "faces_test_flatten = [img.flatten() for img in faces_test]\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.train(np.array(faces_train_flatten), labels_train)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model.save('modelo_eigenfaces7.xml')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "data_dir = 'C:\\\\datasets\\\\archive\\\\train'\n",
    "faces  = os.listdir(data_dir)\n",
    "print(faces)\n",
    "\n",
    "labels = []\n",
    "facesData = []\n",
    "label = 0 \n",
    "for face in faces:\n",
    "    facePath = data_dir+'\\\\'+face # Construye la ruta completa\n",
    "    for faceName in os.listdir(facePath)[:300]: # Toma los primeros 300 archivos\n",
    "        labels.append(label)\n",
    "        facesData.append(cv.imread(facePath+'/'+faceName,0)) # Lee la imagen en escala de grises\n",
    "    label = label + 1\n",
    "print(np.count_nonzero(np.array(labels)==0)) \n",
    "\n",
    "faceRecognizer = cv.face.EigenFaceRecognizer_create()\n",
    "faceRecognizer.train(facesData, np.array(labels))\n",
    "faceRecognizer.save('modelo_eigenfaces8.xml')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feliz', 'sorprendido', 'triste']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "faceRecognizer = cv.face.EigenFaceRecognizer_create()\n",
    "faceRecognizer.read('modelo_eigenfaces9.xml')\n",
    "#data_dir = 'C:\\\\datasets\\\\archive\\\\train'\n",
    "#faces  = os.listdir(data_dir)\n",
    "faces = [\"feliz\", \"sorprendido\", \"triste\"]\n",
    "print(faces)\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "rostro = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_alt.xml')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:break\n",
    "\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    cpGray = gray.copy()\n",
    "\n",
    "    rostros = rostro.detectMultiScale(gray, 1.3, 3)\n",
    "\n",
    "    for (x, y, w, h) in rostros:\n",
    "        frame2 = cpGray[y:y + h, x:x + w]\n",
    "        frame2 = cv.resize(frame2, (100, 100), interpolation=cv.INTER_CUBIC)\n",
    "        result = faceRecognizer.predict(frame2)\n",
    "\n",
    "        if result[1] > 3800: #3800\n",
    "            cv.putText(frame, '{}'.format(faces[result[0]]), (x, y - 25), 2, 1.1, (0, 255, 0), 1, cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv.putText(frame, 'Neutral', (x, y - 20), 2, 0.8, (0, 0, 255), 1, cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    cv.imshow('frame', frame)\n",
    "    # Salir del bucle si se presiona la tecla 'q'\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencv-contrib-python está correctamente instalado.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Verificar si el módulo face de cv2 está disponible\n",
    "try:\n",
    "    face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "    print(\"opencv-contrib-python está correctamente instalado.\")\n",
    "except AttributeError:\n",
    "    print(\"opencv-contrib-python NO está instalado o no se ha importado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "img = cv.imread(\"./assets/fire/fire.13.png\")\n",
    "\n",
    "cv.imshow(\"Display window\", img)\n",
    "k = cv.waitKey(0) # Wait for a keystroke in the window"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
